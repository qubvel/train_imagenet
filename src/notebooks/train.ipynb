{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "sys.path.append('..')\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import ImageNetDataset\n",
    "from utils.transform import train_transform, valid_transform\n",
    "from utils.generator import generator\n",
    "from utils.callbacks import get_callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels mapping\n",
    "with open(config.MAP_CLS) as f:\n",
    "    label_to_class = json.load(f)  \n",
    "folder_to_label = {v[0]: k for k, v in label_to_class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip,  ShiftScaleRotate, RGBShift, CenterCrop,\n",
    "    RandomSizedCrop, SmallestMaxSize, RandomCrop,\n",
    "    ShiftScaleRotate, HueSaturationValue, Normalize,\n",
    "    RandomContrast, RandomBrightness, Flip, OneOf, Compose\n",
    ")\n",
    "\n",
    "train_aug = Compose([\n",
    "    SmallestMaxSize(max_size=256),\n",
    "    ShiftScaleRotate(scale_limit=(0.5, 1), rotate_limit=5),\n",
    "    RandomCrop(224, 224, p=1.0),\n",
    "    HorizontalFlip(0.5),\n",
    "    OneOf([\n",
    "        HueSaturationValue(hue_shift_limit=5, sat_shift_limit=5, val_shift_limit=5, p=1),\n",
    "        RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.5)\n",
    "    ], p=0.2),\n",
    "    OneOf([\n",
    "        RandomBrightness(limit=0.2, p=1.),\n",
    "        RandomContrast(limit=0.2, p=1.),\n",
    "    ], p=0.2),\n",
    "], p = 1.0)\n",
    "\n",
    "\n",
    "valid_aug = Compose([\n",
    "    SmallestMaxSize(max_size=256),\n",
    "    CenterCrop(224, 224, p=1.0),\n",
    "], p = 1.0)\n",
    "\n",
    "\n",
    "def make_transform(preprocessing_fn=None, augmenter=None):\n",
    "    \n",
    "    def transform(**sample):\n",
    "\n",
    "        if augmenter is not None:\n",
    "            sample = augmenter(**sample)\n",
    "\n",
    "        if preprocessing_fn is not None:\n",
    "            sample['image'] = preprocessing_fn(sample['image'].astype('float32')).copy()\n",
    "            \n",
    "        return sample\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity = lambda x: x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_transform = make_transform(augmenter=train_aug, preprocessing_fn=identity)\n",
    "valid_transform = make_transform(augmenter=valid_aug, preprocessing_fn=identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare datasets\n",
    "train_dataset = ImageNetDataset(config.TRAIN_DIR, folder_to_label, transform=train_transform)\n",
    "valid_dataset = ImageNetDataset(config.VALID_DIR, folder_to_label, transform=valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare generators \n",
    "train_gen = generator(train_dataset, batch_size=256, num_workers=12, shuffle=True)\n",
    "valid_gen = generator(valid_dataset, batch_size=16, num_workers=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_models.classification_models import ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, ResNeXt50, ResNeXt101\n",
    "from nn_models.classification_models import SEResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "\n",
    "model = SEResNet18((224, 224, 3))\n",
    "model.load_weights('../../../.keras/models/resnet18_imagenet_1000.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    if l.name.startswith('dense'):\n",
    "        l.trainable = True\n",
    "    else:\n",
    "        l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mg_model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('../../checkpoints/se_resnet18/weights_ep210.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.6, momentum=0.9)\n",
    "mg_model.compile(opt, 'categorical_crossentropy', \n",
    "              ['categorical_accuracy', 'top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "callbacks = get_callbacks('se_resnet18_v2', \n",
    "                          checkpoints_dir=config.CHECKPOINTS_DIR, \n",
    "                          monitor='val_loss',\n",
    "                          log_dir=config.LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "CPU times: user 3.53 s, sys: 1.43 s, total: 4.96 s\n",
      "Wall time: 5.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "valid_gen = generator(valid_dataset, batch_size=16, num_workers=12, shuffle=False)\n",
    "\n",
    "scores = model.evaluate_generator(valid_gen, steps=20) #3125\n",
    "print('{:.4} {:.4}'.format(scores[1], scores[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "1000/1000 [==============================] - 339s 339ms/step - loss: 1.5848 - categorical_accuracy: 0.6269 - top_k_categorical_accuracy: 0.8400 - val_loss: 7.5706 - val_categorical_accuracy: 0.0040 - val_top_k_categorical_accuracy: 0.0163\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.57059, saving model to /home/user/project/checkpoints/se_resnet18_v2/weights-0.004.h5\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 1.5452 - categorical_accuracy: 0.6339 - top_k_categorical_accuracy: 0.8436 - val_loss: 7.9289 - val_categorical_accuracy: 0.0061 - val_top_k_categorical_accuracy: 0.0226\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "1000/1000 [==============================] - 337s 337ms/step - loss: 1.5457 - categorical_accuracy: 0.6337 - top_k_categorical_accuracy: 0.8429 - val_loss: 7.6978 - val_categorical_accuracy: 0.0074 - val_top_k_categorical_accuracy: 0.0231\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "1000/1000 [==============================] - 339s 339ms/step - loss: 1.5355 - categorical_accuracy: 0.6369 - top_k_categorical_accuracy: 0.8449 - val_loss: 7.8669 - val_categorical_accuracy: 0.0107 - val_top_k_categorical_accuracy: 0.0267\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "1000/1000 [==============================] - 341s 341ms/step - loss: 1.5361 - categorical_accuracy: 0.6352 - top_k_categorical_accuracy: 0.8453 - val_loss: 7.7829 - val_categorical_accuracy: 0.0064 - val_top_k_categorical_accuracy: 0.0266\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      "1000/1000 [==============================] - 336s 336ms/step - loss: 1.5300 - categorical_accuracy: 0.6376 - top_k_categorical_accuracy: 0.8455 - val_loss: 7.6857 - val_categorical_accuracy: 0.0081 - val_top_k_categorical_accuracy: 0.0227\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.6000000238418579.\n",
      " 621/1000 [=================>............] - ETA: 1:58 - loss: 1.5383 - categorical_accuracy: 0.6362 - top_k_categorical_accuracy: 0.8450"
     ]
    }
   ],
   "source": [
    "mg_model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=1000, \n",
    "                    initial_epoch=0,\n",
    "                    epochs=10, \n",
    "                    validation_data=valid_gen, \n",
    "                    validation_steps=1000, \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('../../checkpoints/se_resnet18/weights_ep310.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
